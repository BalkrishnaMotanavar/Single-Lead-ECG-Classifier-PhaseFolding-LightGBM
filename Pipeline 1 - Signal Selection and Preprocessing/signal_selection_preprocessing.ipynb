{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6ba5cca-ec39-40c7-b3ab-d245e74e9fda",
   "metadata": {},
   "source": [
    "# Testing lead V6 extraction method on few sample patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "960aac70-ec96-4eb5-8560-2865100013e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Lead V6 extraction and preprocessing on specified patients...\n",
      "Processing record 1/8: 00001_hr\n",
      "Successfully extracted Lead V6 for 00001_hr, length: 5000 samples\n",
      "Processing record 2/8: 00300_hr\n",
      "Successfully extracted Lead V6 for 00300_hr, length: 5000 samples\n",
      "Processing record 3/8: 00092_hr\n",
      "Successfully extracted Lead V6 for 00092_hr, length: 5000 samples\n",
      "Processing record 4/8: 00427_hr\n",
      "Successfully extracted Lead V6 for 00427_hr, length: 5000 samples\n",
      "Processing record 5/8: 00896_hr\n",
      "Successfully extracted Lead V6 for 00896_hr, length: 5000 samples\n",
      "Processing record 6/8: 00900_hr\n",
      "Successfully extracted Lead V6 for 00900_hr, length: 5000 samples\n",
      "Processing record 7/8: 01379_hr\n",
      "Successfully extracted Lead V6 for 01379_hr, length: 5000 samples\n",
      "Processing record 8/8: 01739_hr\n",
      "Successfully extracted Lead V6 for 01739_hr, length: 5000 samples\n"
     ]
    }
   ],
   "source": [
    "import wfdb\n",
    "import numpy as np\n",
    "from scipy import signal as sig\n",
    "from scipy.ndimage import median_filter\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the base path to the PTB-XL dataset\n",
    "base_path = Path(\"/Users/rohanmotanavar/datasets/PTB_XL\")\n",
    "\n",
    "# List of specific patients to test\n",
    "patients = [\n",
    "    \"records500/00000/00001_hr\",\n",
    "    \"records500/00000/00300_hr\",\n",
    "    \"records500/00000/00092_hr\",\n",
    "    \"records500/00000/00427_hr\",\n",
    "    \"records500/00000/00896_hr\",\n",
    "    \"records500/00000/00900_hr\",\n",
    "    \"records500/01000/01379_hr\",\n",
    "    \"records500/01000/01739_hr\"\n",
    "]\n",
    "\n",
    "# Function to preprocess the ECG signal (baseline drift removal and noise reduction)\n",
    "def preprocess_ecg_signal(ecg_signal, fs, median_window_sec=0.2, lowpass_cutoff=40):\n",
    "\n",
    "    try:\n",
    "        # Validate inputs\n",
    "        if not isinstance(ecg_signal, np.ndarray):\n",
    "            raise TypeError(\"Input signal must be a numpy array.\")\n",
    "        if ecg_signal.size == 0:\n",
    "            raise ValueError(\"Input signal is empty.\")\n",
    "        if fs <= 0:\n",
    "            raise ValueError(\"Sampling frequency must be positive.\")\n",
    "        if lowpass_cutoff <= 0 or lowpass_cutoff >= fs / 2:\n",
    "            raise ValueError(\"Low-pass cutoff frequency must be between 0 and Nyquist frequency.\")\n",
    "\n",
    "        # Step 1: Remove baseline drift using median filtering\n",
    "        # Convert window size from seconds to samples\n",
    "        median_window_samples = int(median_window_sec * fs)\n",
    "        # Ensure the window size is odd for median filter\n",
    "        if median_window_samples % 2 == 0:\n",
    "            median_window_samples += 1\n",
    "        # Estimate the baseline using a median filter\n",
    "        baseline = median_filter(ecg_signal, size=median_window_samples)\n",
    "        # Subtract the baseline to remove drift\n",
    "        signal_detrended = ecg_signal - baseline\n",
    "\n",
    "        # Step 2: Remove high-frequency noise using a low-pass filter\n",
    "        nyquist_freq = fs / 2\n",
    "        normalized_lowpass_cutoff = lowpass_cutoff / nyquist_freq\n",
    "        # Design a low-pass Butterworth filter (order 2)\n",
    "        b_low, a_low = sig.butter(2, normalized_lowpass_cutoff, btype='low', analog=False)\n",
    "        # Apply the low-pass filter\n",
    "        filtered_signal = sig.filtfilt(b_low, a_low, signal_detrended)\n",
    "        \n",
    "        return filtered_signal\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in ECG preprocessing: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract Lead V6 and preprocess the signal\n",
    "def extract_lead_v6(record_path, fs=500, plot=False):\n",
    " \n",
    "    try:\n",
    "        # Load the ECG record\n",
    "        record = wfdb.rdrecord(str(record_path))\n",
    "        \n",
    "        # Verify the sampling frequency\n",
    "        if record.fs != fs:\n",
    "            raise ValueError(f\"Sampling frequency mismatch: expected {fs} Hz, got {record.fs} Hz\")\n",
    "        \n",
    "        # Extract the signal data (12 leads)\n",
    "        signals = record.p_signal\n",
    "        \n",
    "        # Verify the number of leads\n",
    "        if signals.shape[1] != 12:\n",
    "            raise ValueError(f\"Expected 12 leads, got {signals.shape[1]} leads\")\n",
    "        \n",
    "        # Extract Lead V6 (index 11: I, II, III, aVR, aVL, aVF, V1-V6)\n",
    "        lead_v6 = signals[:, 11]\n",
    "        \n",
    "        # Preprocess the signal (baseline drift removal and noise reduction)\n",
    "        lead_v6_filtered = preprocess_ecg_signal(lead_v6, fs, median_window_sec=0.2, lowpass_cutoff=40)\n",
    "        \n",
    "        if lead_v6_filtered is None:\n",
    "            raise ValueError(\"Signal preprocessing failed.\")\n",
    "        \n",
    "        # Optional: Plot the original and filtered signals for validation\n",
    "        if plot:\n",
    "            time = np.arange(len(lead_v6)) / fs\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            plt.subplot(2, 1, 1)\n",
    "            plt.plot(time, lead_v6, label=\"Original Lead V6\", color='red')\n",
    "            plt.title(f\"Original Lead V6 - {record_path.name}\")\n",
    "            plt.xlabel(\"Time (s)\")\n",
    "            plt.ylabel(\"Amplitude (mV)\")\n",
    "            plt.grid(True)\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.subplot(2, 1, 2)\n",
    "            plt.plot(time, lead_v6_filtered, label=\"Filtered Lead V6\", color='black')\n",
    "            plt.title(\"Filtered Lead V6 (Baseline Drift and Noise Removed)\")\n",
    "            plt.xlabel(\"Time (s)\")\n",
    "            plt.ylabel(\"Amplitude (mV)\")\n",
    "            plt.grid(True)\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.tight_layout()\n",
    "\n",
    "            # Save the figure\n",
    "            plot_filename = f\"Visualization/{record_path.name}_lead_v6.png\"\n",
    "            plt.savefig(plot_filename)\n",
    "            plt.close()\n",
    "\n",
    "            plt.show()\n",
    "        \n",
    "        return lead_v6_filtered\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {record_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to test the methodology on the specified patients\n",
    "def test_on_specific_patients(base_path, patients_list):\n",
    "\n",
    "    num_patients = len(patients_list)\n",
    "    \n",
    "    for i, patient in enumerate(patients_list):\n",
    "        # Construct the full path to the record\n",
    "        record_path = base_path / patient\n",
    "        print(f\"Processing record {i+1}/{num_patients}: {record_path.name}\")\n",
    "        \n",
    "        # Check if the record exists\n",
    "        if not record_path.with_suffix(\".dat\").exists():\n",
    "            print(f\"Record {record_path} does not exist.\")\n",
    "            continue\n",
    "        \n",
    "        # Extract Lead V6 and preprocess the signal\n",
    "        lead_v6 = extract_lead_v6(record_path, fs=500, plot=True)\n",
    "        \n",
    "        if lead_v6 is not None:\n",
    "            print(f\"Successfully extracted Lead V6 for {record_path.name}, length: {len(lead_v6)} samples\")\n",
    "        else:\n",
    "            print(f\"Failed to extract Lead V6 for {record_path.name}\")\n",
    "\n",
    "# Run the test on the specified patients\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Testing Lead V6 extraction and preprocessing on specified patients...\")\n",
    "    test_on_specific_patients(base_path, patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73133c23-ccdc-4b9c-ad73-9b1807f98094",
   "metadata": {},
   "source": [
    "# Iterating over entire PTB-XL dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08545010-0d73-461f-ac1d-2a134ab07634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing of the entire PTB-XL dataset using ptbxl_database.csv...\n",
      "Loading ptbxl_database.csv...\n",
      "Total records to process: 21799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PTB-XL dataset: 100%|██████████| 21799/21799 [01:57<00:00, 184.77record/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing complete. Successfully processed: 21799/21799 records\n",
      "\n",
      "Saving preprocessed signals to preprocessed_lead_v6.csv for viewing...\n",
      "CSV file saved successfully: preprocessed_lead_v6.csv\n"
     ]
    }
   ],
   "source": [
    "import wfdb\n",
    "import numpy as np\n",
    "from scipy import signal as sig\n",
    "from scipy.ndimage import median_filter\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Define the base path to the PTB-XL dataset and CSV file\n",
    "base_path = Path(\"/Users/rohanmotanavar/datasets/PTB_XL\")\n",
    "csv_path = base_path / \"ptbxl_database.csv\"\n",
    "\n",
    "# Function to preprocess the ECG signal (baseline drift removal and noise reduction)\n",
    "def preprocess_ecg_signal(ecg_signal, fs, median_window_sec=0.2, lowpass_cutoff=40):\n",
    "    \"\"\"\n",
    "    Preprocess an ECG signal by removing baseline drift using median filtering and high-frequency noise.\n",
    "    \n",
    "    Parameters:\n",
    "        ecg_signal (np.ndarray): The ECG signal (1D array).\n",
    "        fs (float): Sampling frequency in Hz.\n",
    "        median_window_sec (float): Window size for median filter in seconds.\n",
    "        lowpass_cutoff (float): Cutoff frequency for the low-pass filter in Hz.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: The preprocessed ECG signal.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate inputs\n",
    "        if not isinstance(ecg_signal, np.ndarray):\n",
    "            raise TypeError(\"Input signal must be a numpy array.\")\n",
    "        if ecg_signal.size == 0:\n",
    "            raise ValueError(\"Input signal is empty.\")\n",
    "        if fs <= 0:\n",
    "            raise ValueError(\"Sampling frequency must be positive.\")\n",
    "        if lowpass_cutoff <= 0 or lowpass_cutoff >= fs / 2:\n",
    "            raise ValueError(\"Low-pass cutoff frequency must be between 0 and Nyquist frequency.\")\n",
    "\n",
    "        # Step 1: Remove baseline drift using median filtering\n",
    "        # Convert window size from seconds to samples\n",
    "        median_window_samples = int(median_window_sec * fs)\n",
    "        # Ensure the window size is odd for median filter\n",
    "        if median_window_samples % 2 == 0:\n",
    "            median_window_samples += 1\n",
    "        # Estimate the baseline using a median filter\n",
    "        baseline = median_filter(ecg_signal, size=median_window_samples)\n",
    "        # Subtract the baseline to remove drift\n",
    "        signal_detrended = ecg_signal - baseline\n",
    "\n",
    "        # Step 2: Remove high-frequency noise using a low-pass filter\n",
    "        nyquist_freq = fs / 2\n",
    "        normalized_lowpass_cutoff = lowpass_cutoff / nyquist_freq\n",
    "        # Design a low-pass Butterworth filter (order 2)\n",
    "        b_low, a_low = sig.butter(2, normalized_lowpass_cutoff, btype='low', analog=False)\n",
    "        # Apply the low-pass filter\n",
    "        filtered_signal = sig.filtfilt(b_low, a_low, signal_detrended)\n",
    "        \n",
    "        return filtered_signal\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in ECG preprocessing: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to extract Lead V6 and preprocess the signal\n",
    "def extract_lead_v6(record_path, fs=500):\n",
    "    \"\"\"\n",
    "    Extract Lead V6 from a PTB-XL record and preprocess the signal.\n",
    "    \n",
    "    Parameters:\n",
    "        record_path (Path): Path to the record (without extension).\n",
    "        fs (float): Expected sampling frequency in Hz.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: The preprocessed Lead V6 signal, or None if processing fails.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the ECG record\n",
    "        record = wfdb.rdrecord(str(record_path))\n",
    "        \n",
    "        # Verify the sampling frequency\n",
    "        if record.fs != fs:\n",
    "            raise ValueError(f\"Sampling frequency mismatch: expected {fs} Hz, got {record.fs} Hz\")\n",
    "        \n",
    "        # Extract the signal data (12 leads)\n",
    "        signals = record.p_signal\n",
    "        \n",
    "        # Verify the number of leads\n",
    "        if signals.shape[1] != 12:\n",
    "            raise ValueError(f\"Expected 12 leads, got {signals.shape[1]} leads\")\n",
    "        \n",
    "        # Extract Lead V6 (index 11: I, II, III, aVR, aVL, aVF, V1-V6)\n",
    "        lead_v6 = signals[:, 11]\n",
    "        \n",
    "        # Preprocess the signal (baseline drift removal and noise reduction)\n",
    "        lead_v6_filtered = preprocess_ecg_signal(lead_v6, fs, median_window_sec=0.2, lowpass_cutoff=40)\n",
    "        \n",
    "        if lead_v6_filtered is None:\n",
    "            raise ValueError(\"Signal preprocessing failed.\")\n",
    "        \n",
    "        return lead_v6_filtered\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {record_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to process the entire dataset using the CSV file and store in HDF5 and CSV with a progress bar\n",
    "def process_entire_dataset(csv_path, base_path, output_hdf5_path=\"preprocessed_lead_v6.h5\", output_csv_path=\"preprocessed_lead_v6.csv\"):\n",
    "    \"\"\"\n",
    "    Process the entire PTB-XL dataset to extract and preprocess Lead V6 for all records,\n",
    "    using the ptbxl_database.csv file to get record paths, and store the results in an HDF5 file\n",
    "    and a CSV file for viewing.\n",
    "    \n",
    "    Parameters:\n",
    "        csv_path (Path): Path to the ptbxl_database.csv file.\n",
    "        base_path (Path): Base path to the PTB-XL dataset.\n",
    "        output_hdf5_path (str): Path to the output HDF5 file.\n",
    "        output_csv_path (str): Path to the output CSV file for viewing.\n",
    "    \"\"\"\n",
    "    # Load the CSV file\n",
    "    print(\"Loading ptbxl_database.csv...\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Extract relevant columns\n",
    "    records = df[['ecg_id', 'patient_id', 'filename_hr']].copy()\n",
    "    total_records = len(records)\n",
    "    print(f\"Total records to process: {total_records}\")\n",
    "\n",
    "    # Initialize a list to store data for the CSV\n",
    "    csv_data = []\n",
    "    signal_length = 5000  # Expected length of each preprocessed Lead V6 signal\n",
    "\n",
    "    # Create the HDF5 file\n",
    "    with h5py.File(output_hdf5_path, 'w') as h5file:\n",
    "        processed_records = 0\n",
    "\n",
    "        # Use tqdm to display a progress bar\n",
    "        with tqdm(total=total_records, desc=\"Processing PTB-XL dataset\", unit=\"record\") as pbar:\n",
    "            for _, row in records.iterrows():\n",
    "                ecg_id = row['ecg_id']\n",
    "                patient_id = row['patient_id']\n",
    "                filename_hr = row['filename_hr']\n",
    "                \n",
    "                # Construct the full path to the record\n",
    "                record_path = base_path / filename_hr\n",
    "                record_name = record_path.name  # e.g., \"00017_hr\"\n",
    "                \n",
    "                # Extract and preprocess Lead V6\n",
    "                lead_v6 = extract_lead_v6(record_path, fs=500)\n",
    "                \n",
    "                if lead_v6 is not None:\n",
    "                    # Store the preprocessed signal in the HDF5 file\n",
    "                    # Use the ecg_id as the dataset key for uniqueness\n",
    "                    dset = h5file.create_dataset(str(ecg_id), data=lead_v6, compression='gzip', compression_opts=4)\n",
    "                    # Store metadata as attributes\n",
    "                    dset.attrs['patient_id'] = patient_id\n",
    "                    dset.attrs['filename_hr'] = filename_hr\n",
    "                    dset.attrs['record_path'] = str(record_path)\n",
    "                    processed_records += 1\n",
    "\n",
    "                    # Prepare data for CSV\n",
    "                    # Create a dictionary with ecg_id, patient_id, filename_hr, and the signal values\n",
    "                    record_data = {\n",
    "                        'ecg_id': ecg_id,\n",
    "                        'patient_id': patient_id,\n",
    "                        'filename_hr': filename_hr\n",
    "                    }\n",
    "                    # Add the signal values as separate columns (sample_0, sample_1, ..., sample_4999)\n",
    "                    for i in range(signal_length):\n",
    "                        record_data[f'sample_{i}'] = lead_v6[i]\n",
    "                    csv_data.append(record_data)\n",
    "                \n",
    "                # Update the progress bar\n",
    "                pbar.update(1)\n",
    "\n",
    "        print(f\"\\nProcessing complete. Successfully processed: {processed_records}/{total_records} records\")\n",
    "\n",
    "    # Step: Save the preprocessed signals to a CSV file for viewing\n",
    "    print(f\"\\nSaving preprocessed signals to {output_csv_path} for viewing...\")\n",
    "    # Create a DataFrame from the collected data\n",
    "    csv_df = pd.DataFrame(csv_data)\n",
    "    # Define the column order: metadata first, then the signal samples\n",
    "    columns = ['ecg_id', 'patient_id', 'filename_hr'] + [f'sample_{i}' for i in range(signal_length)]\n",
    "    csv_df = csv_df[columns]\n",
    "    # Save to CSV\n",
    "    csv_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"CSV file saved successfully: {output_csv_path}\")\n",
    "\n",
    "# Run the processing for the entire dataset\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting processing of the entire PTB-XL dataset using ptbxl_database.csv...\")\n",
    "    process_entire_dataset(csv_path, base_path, output_hdf5_path=\"preprocessed_lead_v6.h5\", output_csv_path=\"preprocessed_lead_v6.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37edaeca-1da0-4bba-a803-b5928ca6dc65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
