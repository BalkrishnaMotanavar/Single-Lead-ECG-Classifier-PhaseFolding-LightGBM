
Fold 1:
Class distribution in y_train (Fold 1):
target
3    8708
2    3760
4    3000
0    2998
1    1158
Name: count, dtype: int64
SMOTE sampling strategy (Fold 1): {np.int64(1): 3000, np.int64(2): np.int64(3760), np.int64(0): 3000, np.int64(4): 3000}
Class distribution after SMOTE+Tomek+UnderSampler (Fold 1):
target
3    6000
2    3057
1    2935
4    2514
0    2471
Name: count, dtype: int64
Classification Report for Fold 1:
              precision    recall  f1-score   support

          CD       0.97      0.97      0.97       324
         HYP       0.77      0.85      0.81       130
          MI       0.96      0.93      0.95       427
        NORM       0.99      1.00      1.00       949
        STTC       0.99      0.98      0.98       345

    accuracy                           0.97      2175
   macro avg       0.94      0.95      0.94      2175
weighted avg       0.97      0.97      0.97      2175

Confusion Matrix for Fold 1:
[[314   5   3   1   1]
 [  5 111  10   4   0]
 [  5  22 396   3   1]
 [  0   0   0 948   1]
 [  0   6   2   0 337]]
Accuracy: 0.968
F1-weighted score: 0.969
Macro F1-score: 0.941
Feature Importance (Top 10):
              feature  importance
9       t_duration_ms    0.071319
10             rr_min    0.023396
6      s_amplitude_mv    0.018458
14  t_inversion_proxy    0.018077
2      q_amplitude_mv    0.008668
4      qt_interval_ms    0.008116
5      r_amplitude_mv    0.007764
1      p_amplitude_mv    0.007607
7     st_elevation_mv    0.007345
3     qrs_duration_ms    0.007055

Fold 2:
Class distribution in y_train (Fold 2):
target
3    8672
2    3783
4    3022
0    2986
1    1155
Name: count, dtype: int64
SMOTE sampling strategy (Fold 2): {np.int64(1): 3000, np.int64(2): np.int64(3783), np.int64(0): 3000, np.int64(4): np.int64(3022)}
Class distribution after SMOTE+Tomek+UnderSampler (Fold 2):
target
3    6000
2    3076
1    2940
4    2535
0    2488
Name: count, dtype: int64
Classification Report for Fold 2:
              precision    recall  f1-score   support

          CD       0.98      0.97      0.97       336
         HYP       0.82      0.90      0.86       133
          MI       0.95      0.94      0.95       404
        NORM       0.99      1.00      0.99       985
        STTC       1.00      0.97      0.98       323

    accuracy                           0.97      2181
   macro avg       0.95      0.96      0.95      2181
weighted avg       0.97      0.97      0.97      2181

Confusion Matrix for Fold 2:
[[326   7   2   1   0]
 [  1 120  11   1   0]
 [  2  17 379   6   0]
 [  3   1   0 981   0]
 [  1   2   5   2 313]]
Accuracy: 0.972
F1-weighted score: 0.972
Macro F1-score: 0.951

Fold 3:
Class distribution in y_train (Fold 3):
target
3    8657
2    3788
4    3033
0    2991
1    1138
Name: count, dtype: int64
SMOTE sampling strategy (Fold 3): {np.int64(1): 3000, np.int64(2): np.int64(3788), np.int64(0): 3000, np.int64(4): np.int64(3033)}
Class distribution after SMOTE+Tomek+UnderSampler (Fold 3):
target
3    6000
2    3106
1    2954
4    2548
0    2496
Name: count, dtype: int64
Classification Report for Fold 3:
              precision    recall  f1-score   support

          CD       0.97      0.96      0.96       331
         HYP       0.81      0.82      0.82       150
          MI       0.93      0.95      0.94       399
        NORM       0.99      1.00      1.00      1000
        STTC       0.99      0.96      0.98       312

    accuracy                           0.97      2192
   macro avg       0.94      0.94      0.94      2192
weighted avg       0.97      0.97      0.97      2192

Confusion Matrix for Fold 3:
[[317   7   3   4   0]
 [  2 123  23   0   2]
 [  5  11 381   2   0]
 [  2   1   0 997   0]
 [  1   9   3   0 299]]
Accuracy: 0.966
F1-weighted score: 0.966
Macro F1-score: 0.939

Fold 4:
Class distribution in y_train (Fold 4):
target
3    8715
2    3761
4    3000
0    2987
1    1162
Name: count, dtype: int64
SMOTE sampling strategy (Fold 4): {np.int64(1): 3000, np.int64(2): np.int64(3761), np.int64(0): 3000, np.int64(4): 3000}
Class distribution after SMOTE+Tomek+UnderSampler (Fold 4):
target
3    6000
2    3049
1    2939
4    2525
0    2481
Name: count, dtype: int64
Classification Report for Fold 4:
              precision    recall  f1-score   support

          CD       0.96      0.94      0.95       335
         HYP       0.80      0.85      0.82       126
          MI       0.94      0.94      0.94       426
        NORM       0.99      1.00      1.00       942
        STTC       1.00      0.98      0.99       345

    accuracy                           0.97      2174
   macro avg       0.94      0.94      0.94      2174
weighted avg       0.97      0.97      0.97      2174

Confusion Matrix for Fold 4:
[[316   7   9   3   0]
 [  5 107  13   0   1]
 [  7  15 402   2   0]
 [  1   2   0 939   0]
 [  0   3   3   1 338]]
Accuracy: 0.967
F1-weighted score: 0.967
Macro F1-score: 0.940

Fold 5:
Class distribution in y_train (Fold 5):
target
3    8701
2    3740
0    3010
4    3001
1    1173
Name: count, dtype: int64
SMOTE sampling strategy (Fold 5): {np.int64(1): 3000, np.int64(2): np.int64(3740), np.int64(0): np.int64(3010), np.int64(4): np.int64(3001)}
Class distribution after SMOTE+Tomek+UnderSampler (Fold 5):
target
3    6000
2    3047
1    2937
4    2524
0    2490
Name: count, dtype: int64
Classification Report for Fold 5:
              precision    recall  f1-score   support

          CD       0.97      0.96      0.97       312
         HYP       0.74      0.90      0.81       115
          MI       0.96      0.92      0.94       447
        NORM       0.99      1.00      1.00       956
        STTC       1.00      0.97      0.98       344

    accuracy                           0.97      2174
   macro avg       0.93      0.95      0.94      2174
weighted avg       0.97      0.97      0.97      2174

Confusion Matrix for Fold 5:
[[300   4   4   4   0]
 [  2 103   9   1   0]
 [  6  26 413   1   1]
 [  0   1   0 955   0]
 [  0   6   4   0 334]]
Accuracy: 0.968
F1-weighted score: 0.969
Macro F1-score: 0.940

Fold 6:
Class distribution in y_train (Fold 6):
target
3    8706
2    3756
4    3020
0    2996
1    1148
Name: count, dtype: int64
SMOTE sampling strategy (Fold 6): {np.int64(1): 3000, np.int64(2): np.int64(3756), np.int64(0): 3000, np.int64(4): np.int64(3020)}
Class distribution after SMOTE+Tomek+UnderSampler (Fold 6):
target
3    6000
2    3057
1    2937
4    2555
0    2481
Name: count, dtype: int64
Classification Report for Fold 6:
              precision    recall  f1-score   support

          CD       0.96      0.97      0.96       326
         HYP       0.81      0.91      0.86       140
          MI       0.96      0.92      0.94       431
        NORM       0.99      1.00      1.00       951
        STTC       0.98      0.96      0.97       325

    accuracy                           0.97      2173
   macro avg       0.94      0.95      0.95      2173
weighted avg       0.97      0.97      0.97      2173

Confusion Matrix for Fold 6:
[[316   5   3   1   1]
 [  2 127   8   1   2]
 [  9  21 396   2   3]
 [  1   0   0 950   0]
 [  1   4   5   2 313]]
Accuracy: 0.967
F1-weighted score: 0.968
Macro F1-score: 0.946

Fold 7:
Class distribution in y_train (Fold 7):
target
3    8674
2    3757
4    3019
0    2995
1    1178
Name: count, dtype: int64
SMOTE sampling strategy (Fold 7): {np.int64(1): 3000, np.int64(2): np.int64(3757), np.int64(0): 3000, np.int64(4): np.int64(3019)}
Class distribution after SMOTE+Tomek+UnderSampler (Fold 7):
target
3    6000
2    3043
1    2942
4    2531
0    2468
Name: count, dtype: int64
Classification Report for Fold 7:
              precision    recall  f1-score   support

          CD       0.98      0.97      0.98       327
         HYP       0.72      0.85      0.78       110
          MI       0.97      0.92      0.94       430
        NORM       0.99      1.00      0.99       983
        STTC       0.99      0.98      0.99       326

    accuracy                           0.97      2176
   macro avg       0.93      0.94      0.94      2176
weighted avg       0.97      0.97      0.97      2176

Confusion Matrix for Fold 7:
[[318   6   0   2   1]
 [  2  93  11   4   0]
 [  3  26 396   4   1]
 [  1   1   0 981   0]
 [  0   3   2   2 319]]
Accuracy: 0.968
F1-weighted score: 0.969
Macro F1-score: 0.936

Fold 8:
Class distribution in y_train (Fold 8):
target
3    8703
2    3776
4    3009
0    2982
1    1156
Name: count, dtype: int64
SMOTE sampling strategy (Fold 8): {np.int64(1): 3000, np.int64(2): np.int64(3776), np.int64(0): 3000, np.int64(4): np.int64(3009)}
Class distribution after SMOTE+Tomek+UnderSampler (Fold 8):
target
3    6000
2    3087
1    2933
4    2549
0    2485
Name: count, dtype: int64
Classification Report for Fold 8:
              precision    recall  f1-score   support

          CD       0.98      0.97      0.97       340
         HYP       0.81      0.86      0.83       132
          MI       0.96      0.95      0.95       411
        NORM       0.99      1.00      1.00       954
        STTC       1.00      0.99      0.99       336

    accuracy                           0.97      2173
   macro avg       0.95      0.95      0.95      2173
weighted avg       0.97      0.97      0.97      2173

Confusion Matrix for Fold 8:
[[329   8   2   1   0]
 [  2 113  15   2   0]
 [  4  14 390   3   0]
 [  1   1   0 952   0]
 [  0   4   0   0 332]]
Accuracy: 0.974
F1-weighted score: 0.974
Macro F1-score: 0.950

Fold 9:
Class distribution in y_train (Fold 9):
target
3    8692
2    3786
4    3007
0    2982
1    1149
Name: count, dtype: int64
SMOTE sampling strategy (Fold 9): {np.int64(1): 3000, np.int64(2): np.int64(3786), np.int64(0): 3000, np.int64(4): np.int64(3007)}
Class distribution after SMOTE+Tomek+UnderSampler (Fold 9):
target
3    6000
2    3104
1    2948
4    2526
0    2467
Name: count, dtype: int64
Classification Report for Fold 9:
              precision    recall  f1-score   support

          CD       0.97      0.97      0.97       340
         HYP       0.85      0.86      0.86       139
          MI       0.96      0.95      0.96       401
        NORM       0.99      1.00      1.00       965
        STTC       1.00      0.99      0.99       338

    accuracy                           0.97      2183
   macro avg       0.95      0.95      0.95      2183
weighted avg       0.97      0.97      0.97      2183

Confusion Matrix for Fold 9:
[[329   5   1   4   1]
 [  4 120  14   1   0]
 [  4  13 382   2   0]
 [  1   0   0 964   0]
 [  0   3   1   1 333]]
Accuracy: 0.975
F1-weighted score: 0.975
Macro F1-score: 0.954

Fold 10:
Class distribution in y_train (Fold 10):
target
3    8685
2    3776
4    2994
0    2971
1    1175
Name: count, dtype: int64
SMOTE sampling strategy (Fold 10): {np.int64(1): 3000, np.int64(2): np.int64(3776), np.int64(0): 3000, np.int64(4): 3000}
Class distribution after SMOTE+Tomek+UnderSampler (Fold 10):
target
3    6000
2    3072
1    2948
4    2515
0    2458
Name: count, dtype: int64
Classification Report for Fold 10:
              precision    recall  f1-score   support

          CD       0.97      0.96      0.96       351
         HYP       0.77      0.84      0.80       113
          MI       0.96      0.94      0.95       411
        NORM       0.99      1.00      0.99       972
        STTC       1.00      0.97      0.99       351

    accuracy                           0.97      2198
   macro avg       0.94      0.94      0.94      2198
weighted avg       0.97      0.97      0.97      2198

Confusion Matrix for Fold 10:
[[337   8   3   3   0]
 [  4  95  12   2   0]
 [  5  17 388   1   0]
 [  3   0   0 969   0]
 [  0   4   3   2 342]]
Accuracy: 0.970
F1-weighted score: 0.970
Macro F1-score: 0.939

Overall Confusion Matrix:
[[3202   62   30   24    4]
 [  29 1112  126   16    5]
 [  50  182 3923   26    6]
 [  13    7    0 9636    1]
 [   3   44   28   10 3260]]

Summary of 10-Fold Cross-Validation:
Accuracy scores: [0.968, 0.972, 0.966, 0.967, 0.968, 0.967, 0.968, 0.974, 0.975, 0.97]
Mean Accuracy: 0.969 (±0.003)
F1-weighted scores: [0.969, 0.972, 0.966, 0.967, 0.969, 0.968, 0.969, 0.974, 0.975, 0.97]
Mean F1-weighted score: 0.970 (±0.003)
Macro F1-scores: [0.941, 0.951, 0.939, 0.94, 0.94, 0.946, 0.936, 0.95, 0.954, 0.939]
Mean Macro F1-score: 0.943 (±0.006)
